# Terminal Guidance - Drone Companion Computer Configuration
# =========================================================

# Camera Input Configuration
camera:
  # Camera source - can be:
  # - RTSP URL: "rtsp://192.168.1.10:554/stream"
  # - Webcam index: "0" (or "1", "2", etc.)
  # - Video file: "/path/to/video.mp4"
  # - HTTP MJPEG: "http://192.168.1.129:8554/stream"
  rtsp_url: "rtsp://root:12345@192.168.2.10/stream=0"

  # Camera specifications (used for FOV calculations)
  resolution:
    width: 1280
    height: 720

  # Horizontal and vertical field of view in degrees
  fov:
    horizontal: 90.0
    vertical: 60.0

  # Capture settings
  fps: 30
  buffer_size: 1  # Keep low for minimal latency

  # Reconnection settings
  reconnect_attempts: 5
  reconnect_delay_sec: 2.0

# Detection Model Configuration
# =============================
# Performance on Raspberry Pi 5:
#   NCNN (FP32):    ~130-160ms/frame (~6-8 FPS detection)
#   TFLite INT8:    ~28ms/frame (~35 FPS detection) - RECOMMENDED
#
# To use TFLite INT8:
#   1. Run: python scripts/convert_to_tflite.py --int8
#   2. Set backend: "tflite" below
#
detector:
  # Model selection: yolo11n (recommended), yolo11s, yolov8n, yolov8s
  # YOLO11n is fastest on ARM, best accuracy/speed tradeoff
  model: "yolo11n"

  # Backend: "ncnn" (default), "openvino", "pytorch"
  backend: "ncnn"

  # Path to custom model weights (optional, uses default if empty)
  # For NCNN: "yolo11n_ncnn_model"
  # For TFLite: "yolo11n_int8.tflite"
  weights_path: "yolo11n_ncnn_model"

  # Auto-export to NCNN format on first run (~4x faster on ARM)
  auto_export_ncnn: false

  # Inference settings
  confidence_threshold: 0.5
  nms_threshold: 0.45

  # Target classes to detect (COCO class names)
  # Empty list = detect all classes
  target_classes:
    - "person"
    - "car"
    - "truck"
    - "boat"

  # Model input resolution (with NCNN backend)
  # 640 = best for distance (~160ms)
  # 416 = balanced (~100ms)
  # 192 = close-range only (~50ms, fastest)
  input_size: 640

  # FP16 - not supported on Pi CPU, keep false
  half_precision: false

  # Performance: run detection every N frames (1 = every frame)
  # Higher values reduce CPU load, tracker interpolates between
  # Recommended: 3-5 for 30fps input (gives 6-10 detections/sec)
  detection_interval: 3

  # Detection resolution (downscale camera frame before detection)
  # This is independent of input_size - frame is resized to this first,
  # then model resizes to input_size. Keep equal to input_size for best quality.
  detection_resolution:
    width: 640
    height: 640

  # ROI detection: when locked, only scan area around target
  # Significantly faster when tracking (smaller area to process)
  roi_detection:
    enabled: true
    padding_percent: 50  # Extra area around target bbox

# Target Tracking Configuration
tracker:
  # Tracking algorithm: "centroid" (simple, fast) or "bytetrack" (Kalman, better occlusion handling)
  algorithm: "bytetrack"

  # Max frames to keep tracking without detection
  max_disappeared: 30

  # Distance threshold for object association (pixels, used by centroid tracker)
  max_distance: 150

  # Lock-on settings
  lock_on:
    # Minimum confidence to initiate lock
    min_confidence: 0.6
    # Frames target must be visible before lock
    frames_to_lock: 5
    # Frames without target before losing lock
    frames_to_unlock: 15

  # ByteTrack-specific settings (only used when algorithm: "bytetrack")
  bytetrack:
    high_thresh: 0.5   # High confidence threshold for first association pass
    low_thresh: 0.1    # Low confidence threshold for second pass (catches occluded objects)
    match_thresh: 0.8  # IoU threshold for track-detection matching

# PID Controller Configuration
pid:
  # Yaw control (horizontal centering)
  yaw:
    kp: 0.5
    ki: 0.01
    kd: 0.1
    max_rate: 30.0  # Max yaw rate in deg/sec
    derivative_filter: 0.1  # Low-pass filter (0=heavy filtering, 1=none)
    slew_rate: 60.0  # Max rate change per second (deg/sec^2)

  # Pitch control (vertical centering)
  pitch:
    kp: 0.4
    ki: 0.01
    kd: 0.08
    max_rate: 20.0  # Max pitch rate in deg/sec
    derivative_filter: 0.1
    slew_rate: 40.0

  # Throttle control (distance/altitude)
  throttle:
    kp: 0.3
    ki: 0.005
    kd: 0.05
    max_rate: 2.0  # Max climb rate in m/sec
    derivative_filter: 0.2  # Less filtering for altitude (more responsive)
    slew_rate: 4.0

  # Dead zone - no correction if target within this % of center
  dead_zone_percent: 5.0

  # Control update rate (Hz)
  update_rate: 20

# MAVLink Configuration
mavlink:
  # Connection string to flight controller
  connection: "udp:192.168.1.1:14550"

  # System/Component IDs
  source_system: 255
  source_component: 190

  # Heartbeat rate (Hz)
  heartbeat_rate: 1.0

  # Command timeout (seconds)
  command_timeout: 5.0

  # Enable actual control commands (set false for testing)
  enable_control: false

# Safety Configuration
safety:
  # Action when target is lost: hover, loiter, rtl, continue_last, land
  target_lost_action: "loiter"

  # Maximum time to search for lost target before safety action (seconds)
  search_timeout: 10.0

  # Geofence settings
  geofence:
    enabled: true
    max_distance_m: 500  # Max distance from home
    max_altitude_m: 120  # Max altitude AGL
    min_altitude_m: 10   # Min altitude AGL

  # Emergency stop - immediately halt all tracking
  emergency_stop_enabled: true

  # Minimum battery percentage before forced RTL
  min_battery_percent: 20

  # Maximum tracking speed (m/s)
  max_tracking_speed: 10.0

  # Require ARM confirmation before tracking
  require_arm_confirmation: true

# Output Stream Configuration
output:
  # UDP H.264 stream to QGroundControl
  # QGC Settings: Video Source = UDP h.264, Port = 5600
  stream:
    enabled: true
    udp_host: "192.168.1.129"  # Mac running QGC
    udp_port: 5600

  # Output resolution (independent of input)
  resolution:
    width: 1280
    height: 720

  fps: 30
  bitrate_kbps: 2000

  # Encoding: h264, h265
  codec: "h264"

  # Hardware encoding (Pi 5 does NOT have h264_v4l2m2m, uses libx264)
  # This setting is currently unused - software encoding is always used
  hardware_encode: false

  # Overlay settings
  overlay:
    show_detections: true
    show_locked_target: true
    show_tracking_info: true
    show_telemetry: true
    font_scale: 0.6
    box_thickness: 2

# Web UI Configuration (config-only, video goes direct to QGC via UDP)
web:
  enabled: true
  host: "0.0.0.0"
  port: 5000

# Logging Configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  file: "logs/terminal_guidance.log"
  max_size_mb: 10
  backup_count: 3

  # Log performance metrics
  log_performance: true
  performance_interval_sec: 30

# System Configuration
system:
  # Threading settings
  max_workers: 4

  # GPU acceleration (if available)
  use_gpu: false

  # Performance mode: balanced, performance, power_save
  performance_mode: "balanced"
